"""
Temporal Super Resolution Dataset Library

ì‚¬ìš©ë²•:
    from temporal_dataset import create_temporal_dataset, TemporalDataset
    
    # ê°„ë‹¨ ì‚¬ìš©
    train_loader, val_loader, test_loader = create_temporal_dataset("data.npy")
    
    # ì»¤ìŠ¤í„°ë§ˆì´ì§•
    datasets = TemporalDataset.from_file("data.npy", train_ratio=0.7)
    train_loader = datasets.get_train_loader(batch_size=16)
"""

import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
from pathlib import Path
import warnings

class TemporalSuperResolutionDataset(Dataset):
    """
    Temporal Super Resolutionì„ ìœ„í•œ PyTorch Dataset
    temporal_strideì— ë”°ë¼:
    - stride=1: t1, t6 â†’ t2, t3, t4, t5
    - stride=2: t1, t11 â†’ t3, t5, t7, t9
    - stride=3: t1, t16 â†’ t4, t7, t10, t13
    """
    
    def __init__(self, data, sequence_length=6, temporal_stride=1, normalize=True, split_stats=None):
        """
        Parameters:
        data: numpy array (timestep, 1, grid_x, grid_y) ë˜ëŠ” (timestep, grid_x, grid_y)
        sequence_length: ì¶œë ¥í•  í”„ë ˆì„ ìˆ˜ (ê¸°ë³¸ê°’: 6, ì…ë ¥ 2ê°œ + íƒ€ê²Ÿ 4ê°œ)
        temporal_stride: í”„ë ˆì„ ê°„ ê°„ê²© (ê¸°ë³¸ê°’: 1)
        normalize: ì •ê·œí™” ì—¬ë¶€
        split_stats: {'mean': float, 'std': float} ì „ì²´ ë°ì´í„°ì˜ í†µê³„
        """
        self.data = self._validate_data(data)
        self.sequence_length = sequence_length
        self.temporal_stride = temporal_stride
        self.normalize = normalize
        
        # ì‹¤ì œ í•„ìš”í•œ í”„ë ˆì„ ë²”ìœ„
        self.actual_sequence_length = (sequence_length - 1) * temporal_stride + 1
        
        # ìœ íš¨í•œ ì‹œì‘ ì¸ë±ìŠ¤ ê³„ì‚°
        self.valid_indices = list(range(len(self.data) - self.actual_sequence_length + 1))
        
        # ì •ê·œí™” í†µê³„
        if self.normalize:
            if split_stats is not None:
                self.mean = split_stats['mean']
                self.std = split_stats['std']
            else:
                self.mean = np.mean(self.data)
                self.std = np.std(self.data)
    
    def _validate_data(self, data):
        """ë°ì´í„° í˜•íƒœ ê²€ì¦ ë° ë³€í™˜"""
        if len(data.shape) == 3:
            # (timestep, grid_x, grid_y) -> (timestep, 1, grid_x, grid_y)
            data = data[:, np.newaxis, :, :]
        elif len(data.shape) == 4:
            # (timestep, C, grid_x, grid_y) - CëŠ” ì„ì˜ì˜ ì±„ë„ ìˆ˜ ê°€ëŠ¥ (u, v, p ë“±)
            pass  # ì´ë¯¸ ì˜¬ë°”ë¥¸ í˜•íƒœ
        else:
            raise ValueError(f"ë°ì´í„°ëŠ” 3D ë˜ëŠ” 4Dì—¬ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {data.shape}")

        return data
    
    def __len__(self):
        return len(self.valid_indices)
    
    def __getitem__(self, idx):
        start_idx = self.valid_indices[idx]

        # strideë¥¼ ê³ ë ¤í•œ ì‹œí€€ìŠ¤ ì¶”ì¶œ
        indices = [start_idx + i * self.temporal_stride for i in range(self.sequence_length)]
        sequence = self.data[indices]  # (seq_len, C, H, W)

        # ì •ê·œí™”
        if self.normalize:
            sequence = (sequence - self.mean) / self.std

        # Input/Target ë¶„ë¦¬
        input_frames = np.stack([sequence[0], sequence[-1]], axis=0)  # (2, C, H, W)
        target_frames = sequence[1:-1]  # (num_target_frames, C, H, W)

        # Input: 2ê°œ í”„ë ˆì„ì˜ ì±„ë„ì„ concat (2, C, H, W) -> (2*C, H, W)
        input_concat = input_frames.reshape(-1, input_frames.shape[2], input_frames.shape[3])

        # Target: ëª¨ë“  í”„ë ˆì„ì˜ ì±„ë„ì„ flatten (num_target_frames, C, H, W) -> (num_target_frames*C, H, W)
        target_concat = target_frames.reshape(-1, target_frames.shape[2], target_frames.shape[3])

        return {
            'input': torch.FloatTensor(input_concat),  # (2*C, H, W)
            'target': torch.FloatTensor(target_concat),  # (num_target_frames*C, H, W)
            'sequence_idx': start_idx,
            'stride': self.temporal_stride,
            'num_frames': target_frames.shape[0],  # ë‚˜ì¤‘ì— unflattení•˜ê¸° ìœ„í•´
            'channels_per_frame': target_frames.shape[1]  # ë‚˜ì¤‘ì— unflattení•˜ê¸° ìœ„í•´
        }
    
    def denormalize(self, normalized_data):
        """ì •ê·œí™” í•´ì œ"""
        if self.normalize:
            return normalized_data * self.std + self.mean
        return normalized_data
    
    def get_info(self):
        """ë°ì´í„°ì…‹ ì •ë³´ ë°˜í™˜"""
        if len(self) > 0:
            sample = self[0]
            input_shape = sample['input'].shape
            target_shape = sample['target'].shape
        else:
            input_shape = (2, 1, 0, 0)
            target_shape = (4, 1, 0, 0)
        
        return {
            'sequences': len(self),
            'timesteps': self.data.shape[0],
            'grid_size': (self.data.shape[2], self.data.shape[3]),
            'input_shape': input_shape,
            'target_shape': target_shape,
            'normalized': self.normalize,
            'temporal_stride': self.temporal_stride,
            'actual_sequence_length': self.actual_sequence_length
        }

class TemporalDataset:
    """
    Temporal Dataset ê´€ë¦¬ í´ë˜ìŠ¤
    """
    
    def __init__(self, train_dataset, val_dataset, test_dataset):
        self.train_dataset = train_dataset
        self.val_dataset = val_dataset  
        self.test_dataset = test_dataset
    

    @classmethod
    def from_file(cls, data, sequence_length=6, temporal_stride=1, normalize=True,
                  train_ratio=0.6, val_ratio=0.2, test_ratio=0.2):
        """
        íŒŒì¼ì—ì„œ ë°ì´í„°ì…‹ ìƒì„±

        Parameters:
        data: ë°ì´í„° ë°°ì—´
        sequence_length: ì‹œí€€ìŠ¤ ê¸¸ì´
        temporal_stride: í”„ë ˆì„ ê°„ê²© (ì¶”ê°€ë¨)
        normalize: ì •ê·œí™” ì—¬ë¶€
        train_ratio, val_ratio, test_ratio: ë¶„í•  ë¹„ìœ¨

        Returns:
        TemporalDataset ê°ì²´
        """

        # ì‹œê°„ìˆœ ë¶„í• 
        total_timesteps = data.shape[0]
        train_end = int(total_timesteps * train_ratio)
        val_end = int(total_timesteps * (train_ratio + val_ratio))

        train_data = data[:train_end]
        val_data = data[train_end:val_end]
        test_data = data[val_end:]

        print(f"ğŸ“Š ë°ì´í„° ë¶„í• :")
        print(f"   Train: {train_data.shape[0]} frames ({train_ratio*100:.1f}%)")
        print(f"   Val:   {val_data.shape[0]} frames ({val_ratio*100:.1f}%)")
        print(f"   Test:  {test_data.shape[0]} frames ({test_ratio*100:.1f}%)")

        # ì „ì²´ í†µê³„ ê³„ì‚°
        split_stats = None
        if normalize:
            split_stats = {
                'mean': np.mean(data),
                'std': np.std(data)
            }

        # ë°ì´í„°ì…‹ ìƒì„± - temporal_stride ì „ë‹¬
        train_dataset = TemporalSuperResolutionDataset(
            train_data, sequence_length, temporal_stride, normalize, split_stats
        )
        val_dataset = TemporalSuperResolutionDataset(
            val_data, sequence_length, temporal_stride, normalize, split_stats
        )
        test_dataset = TemporalSuperResolutionDataset(
            test_data, sequence_length, temporal_stride, normalize, split_stats
        )

        print(f"ğŸ¯ ì‹œí€€ìŠ¤ ìƒì„± (stride={temporal_stride}):")
        print(f"   Train: {len(train_dataset)} sequences")
        print(f"   Val:   {len(val_dataset)} sequences")
        print(f"   Test:  {len(test_dataset)} sequences")

        # stride ì •ë³´ ì¶œë ¥
        actual_length = (sequence_length - 1) * temporal_stride + 1
        print(f"   ê° ì‹œí€€ìŠ¤ëŠ” {actual_length} í”„ë ˆì„ ë²”ìœ„ë¥¼ ì»¤ë²„")

        return cls(train_dataset, val_dataset, test_dataset)
   
    
    def get_train_loader(self, batch_size=8, shuffle=True, num_workers=0, **kwargs):
        """Train DataLoader ë°˜í™˜"""
        return DataLoader(self.train_dataset, batch_size=batch_size, 
                         shuffle=shuffle, num_workers=num_workers, **kwargs)
    
    def get_val_loader(self, batch_size=8, shuffle=False, num_workers=0, **kwargs):
        """Validation DataLoader ë°˜í™˜"""
        return DataLoader(self.val_dataset, batch_size=batch_size,
                         shuffle=shuffle, num_workers=num_workers, **kwargs)
    
    def get_test_loader(self, batch_size=8, shuffle=False, num_workers=0, **kwargs):
        """Test DataLoader ë°˜í™˜"""
        return DataLoader(self.test_dataset, batch_size=batch_size,
                         shuffle=shuffle, num_workers=num_workers, **kwargs)
    
    def get_all_loaders(self, batch_size=8, num_workers=0, **kwargs):
        """ëª¨ë“  DataLoader ë°˜í™˜"""
        train_loader = self.get_train_loader(batch_size, True, num_workers, **kwargs)
        val_loader = self.get_val_loader(batch_size, False, num_workers, **kwargs)
        test_loader = self.get_test_loader(batch_size, False, num_workers, **kwargs)
        return train_loader, val_loader, test_loader
    
    def visualize_sample(self, split='train', sample_idx=0, figsize=(15, 8)):
        """ìƒ˜í”Œ ì‹œê°í™”"""
        if split == 'train':
            dataset = self.train_dataset
        elif split == 'val':
            dataset = self.val_dataset
        elif split == 'test':
            dataset = self.test_dataset
        else:
            raise ValueError("splitì€ 'train', 'val', 'test' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        
        if len(dataset) == 0:
            print(f"âš ï¸  {split} ë°ì´í„°ì…‹ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return
        
        if sample_idx >= len(dataset):
            sample_idx = 0
            warnings.warn(f"sample_idxê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ 0ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.")
        
        sample = dataset[sample_idx]
        input_frames = sample['input'].numpy()
        target_frames = sample['target'].numpy()
        
        # ì •ê·œí™” í•´ì œ
        if dataset.normalize:
            input_frames = dataset.denormalize(input_frames)
            target_frames = dataset.denormalize(target_frames)
        
        # ì‹œê°í™”
        fig, axes = plt.subplots(2, 3, figsize=figsize)
        fig.suptitle(f'{split.capitalize()} Sample {sample_idx}')
        
        # Input frames
        im1 = axes[0, 0].imshow(input_frames[0, 0], cmap='RdBu', origin='lower')
        axes[0, 0].set_title('Input: t1')
        plt.colorbar(im1, ax=axes[0, 0])
        
        im2 = axes[0, 1].imshow(input_frames[1, 0], cmap='RdBu', origin='lower')
        axes[0, 1].set_title('Input: t6')
        plt.colorbar(im2, ax=axes[0, 1])
        
        # Difference
        diff = input_frames[1, 0] - input_frames[0, 0]
        im3 = axes[0, 2].imshow(diff, cmap='RdBu', origin='lower')
        axes[0, 2].set_title('Difference (t6-t1)')
        plt.colorbar(im3, ax=axes[0, 2])
        
        # Target frames (ì¼ë¶€ë§Œ)
        target_indices = [0, 1, 3]  # t2, t3, t5
        target_labels = ['t2', 't3', 't5']
        
        for i, (idx, label) in enumerate(zip(target_indices, target_labels)):
            im = axes[1, i].imshow(target_frames[idx, 0], cmap='RdBu', origin='lower')
            axes[1, i].set_title(f'Target: {label}')
            plt.colorbar(im, ax=axes[1, i])
        
        plt.tight_layout()
        plt.show()
        
        # í†µê³„ ì¶œë ¥
        print(f"\nğŸ“Š {split.capitalize()} Sample {sample_idx} í†µê³„:")
        print(f"   Input range:  {input_frames.min():.4f} ~ {input_frames.max():.4f}")
        print(f"   Target range: {target_frames.min():.4f} ~ {target_frames.max():.4f}")
    
    def get_info(self):
        """ì „ì²´ ë°ì´í„°ì…‹ ì •ë³´"""
        train_info = self.train_dataset.get_info()
        val_info = self.val_dataset.get_info()
        test_info = self.test_dataset.get_info()
        
        return {
            'train': train_info,
            'val': val_info,
            'test': test_info,
            'total_sequences': train_info['sequences'] + val_info['sequences'] + test_info['sequences']
        }
    
    def print_info(self):
        """ì •ë³´ ì¶œë ¥"""
        info = self.get_info()
        
        print("="*50)
        print("ğŸ“‹ Temporal Super Resolution Dataset Info")
        print("="*50)
        print(f"ğŸ¯ Task: t1, t6 â†’ t2, t3, t4, t5")
        print(f"ğŸ“Š Total sequences: {info['total_sequences']}")
        
        for split in ['train', 'val', 'test']:
            split_info = info[split]
            print(f"\n{split.capitalize()}:")
            print(f"   Sequences: {split_info['sequences']}")
            print(f"   Timesteps: {split_info['timesteps']}")
            print(f"   Grid size: {split_info['grid_size']}")
            if split_info['sequences'] > 0:
                print(f"   Input shape: {split_info['input_shape']}")
                print(f"   Target shape: {split_info['target_shape']}")

# í¸ì˜ í•¨ìˆ˜ë“¤

def create_temporal_dataset(data_file, batch_size=8, sequence_length=6, 
                           temporal_stride=1, normalize=True,
                           train_ratio=0.6, val_ratio=0.2, test_ratio=0.2,
                           num_workers=0, **kwargs):
    """
    Parameters ì¶”ê°€:
    temporal_stride: í”„ë ˆì„ ê°„ê²© (1, 2, 3, ...)
        - stride=1: ì—°ì† í”„ë ˆì„ (t1, t2, t3, ...)
        - stride=2: í•œ ì¹¸ ë„ì›Œì„œ (t1, t3, t5, ...)
        - stride=3: ë‘ ì¹¸ ë„ì›Œì„œ (t1, t4, t7, ...)
    """
    print(f"ğŸš€ Temporal Super Resolution ë°ì´í„°ì…‹ ìƒì„± (stride={temporal_stride})")
    
    if temporal_stride == 1:
        print(f"   Input: t1, t{sequence_length}")
        print(f"   Target: t2 ~ t{sequence_length-1}")
    else:
        end_frame = 1 + (sequence_length - 1) * temporal_stride
        target_frames = [1 + (i+1) * temporal_stride for i in range(sequence_length - 2)]
        print(f"   Input: t1, t{end_frame}")
        print(f"   Target: t{target_frames}")
    
    # ë°ì´í„°ì…‹ ìƒì„± - from_file ë©”ì„œë“œë„ ìˆ˜ì • í•„ìš”
    datasets = TemporalDataset.from_file(
        data_file, sequence_length, temporal_stride, normalize,
        train_ratio, val_ratio, test_ratio
    )
    
    # DataLoader ìƒì„±
    train_loader, val_loader, test_loader = datasets.get_all_loaders(
        batch_size=batch_size, num_workers=num_workers, **kwargs
    )
    
    print(f"âœ… DataLoader ìƒì„± ì™„ë£Œ (batch_size={batch_size})")
    return train_loader, val_loader, test_loader


def quick_visualize(data_file, split='train', sample_idx=0, **dataset_kwargs):
    """
    ë¹ ë¥¸ ì‹œê°í™”ë¥¼ ìœ„í•œ í¸ì˜ í•¨ìˆ˜
    
    Parameters:
    data_file: ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    split: 'train', 'val', 'test'
    sample_idx: ìƒ˜í”Œ ì¸ë±ìŠ¤
    **dataset_kwargs: TemporalDataset.from_fileì— ì „ë‹¬í•  ì¸ì
    """
    datasets = TemporalDataset.from_file(data_file, **dataset_kwargs)
    datasets.visualize_sample(split, sample_idx)
    return datasets

# ë²„ì „ ì •ë³´
def get_version():
    """ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ë°˜í™˜"""
    return __version__

def print_usage():
    """ì‚¬ìš©ë²• ì¶œë ¥"""
    print("""
ğŸ”¥ Temporal Dataset Library ì‚¬ìš©ë²•

1ï¸âƒ£ ê°„ë‹¨ ì‚¬ìš©:
   from temporal_dataset import create_temporal_dataset
   
   train_loader, val_loader, test_loader = create_temporal_dataset("data.npy")

2ï¸âƒ£ ì»¤ìŠ¤í„°ë§ˆì´ì§•:
   from temporal_dataset import TemporalDataset
   
   datasets = TemporalDataset.from_file("data.npy", train_ratio=0.7)
   train_loader = datasets.get_train_loader(batch_size=16)
   datasets.visualize_sample('train', 0)
   datasets.print_info()

3ï¸âƒ£ ë¹ ë¥¸ ì‹œê°í™”:
   from temporal_dataset import quick_visualize
   
   quick_visualize("data.npy", split='train')

ğŸ“š ì£¼ìš” ê¸°ëŠ¥:
   - 6:2:2 ì‹œê°„ìˆœ ë°ì´í„° ë¶„í• 
   - t1,t6 â†’ t2,t3,t4,t5 temporal super resolution
   - ìë™ ì •ê·œí™” (ì „ì²´ ë°ì´í„° í†µê³„ ì‚¬ìš©)
   - ì‹œê°í™” ë° ì •ë³´ ì¶œë ¥
   - PyTorch DataLoader ìë™ ìƒì„±
""")

if __name__ == "__main__":
    print_usage()
    print(f"\nğŸ“¦ Temporal Dataset Library v{__version__}")
    print(f"ğŸ‘¨â€ğŸ’» Created by {__author__}")
